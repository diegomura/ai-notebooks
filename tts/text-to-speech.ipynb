{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Speech Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input text\n",
    "\n",
    "text = open('the-name-of-the-wind.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-to-speech\", model=\"suno/bark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Generate audio\n",
    "output = pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import wave\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "audio_obj = Audio(output[\"audio\"], rate=output[\"sampling_rate\"])\n",
    "\n",
    "with wave.open('bark.wav', 'wb') as wf:\n",
    "    wf.setnchannels(1)  # Mono audio\n",
    "    wf.setsampwidth(2)  # 16-bit audio\n",
    "    wf.setframerate(output[\"sampling_rate\"])  # Sample rate (adjust as needed)\n",
    "    wf.writeframes(audio_obj.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeechT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try speecht5\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "synthesiser = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\")\n",
    "embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embedding = torch.tensor(embeddings_dataset[0][\"xvector\"]).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can replace this embedding with your own as well.\n",
    "\n",
    "speech = synthesiser(text, forward_params={\"speaker_embeddings\": speaker_embedding})\n",
    "\n",
    "sf.write(\"speech5.wav\", speech[\"audio\"], samplerate=speech[\"sampling_rate\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
